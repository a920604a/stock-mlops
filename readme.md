

# Stock Price Prediction with MLOps

## ğŸ¯ Course Project

### Objective

The goal of this project is to apply everything learned in the course to build an end-to-end machine learning system with full MLOps workflow.

---

## ğŸ“ Problem Statement

This project aims to build a sustainable and maintainable stock price prediction system, implementing the complete MLOps lifecycle including data collection, feature engineering, model training, experiment tracking, real-time inference, deployment, and monitoring.

Users can query predicted stock prices and historical trend charts through a web interface. Developers can periodically retrain models, track experiments, monitor performance and data drift, and trigger auto-retraining.

---

## ğŸ§° Technologies Used

| Category                   | Tools & Frameworks                                                |
| -------------------------- | ----------------------------------------------------------------- |
| **Cloud / Infra**          | Docker Compose (extendable to EC2), MinIO, PostgreSQL, ClickHouse |
| **ML Pipeline**            | FastAPI, Scikit-learn, Pandas, MLflow                             |
| **Workflow Orchestration** | Prefect 2                                                         |
| **Monitoring**             | Evidently + Prometheus + Grafana                                  |
| **CI/CD**                  | GitHub Actions                                                    |
| **Testing**                | pytest (unit + integration tests)                                 |
| **Formatting / Hooks**     | black, pre-commit, flake8                                         |
| **IaC**                    | Docker Compose + Volume + Network (extendable to Terraform)       |

---

## ğŸ—ï¸ Project Structure

```
.
â”œâ”€â”€ backend/                  # Backend with API, ML logic, workflows
â”‚   â”œâ”€â”€ api/                  # FastAPI routes (train, predict)
â”‚   â”œâ”€â”€ src/                  # Feature engineering, model training/inference
â”‚   â”œâ”€â”€ monitor/              # Monitoring logic using Evidently
â”‚   â”œâ”€â”€ tasks/                # Celery async tasks
â”‚   â”œâ”€â”€ workflows/            # Prefect ETL & training flows
â”‚   â””â”€â”€ tests/                # Unit & integration tests
â”œâ”€â”€ frontend/                 # Frontend (Vite + React)
â”œâ”€â”€ data/, db/, pgdata/       # Data and DB initialization folders
â”œâ”€â”€ monitor/                  # Prometheus & Grafana configurations
â”œâ”€â”€ Dockerfile.*, docker-compose.yml
â”œâ”€â”€ Makefile, setup.md, implementation_log.md
â”œâ”€â”€ README.md
```

---

## ğŸ” Model Lifecycle

1. ETL and training pipelines are triggered regularly via Prefect
2. Training results are logged to MLflow and registered as versioned models
3. FastAPI serves `/predict` and `/train` APIs (Celery-supported)
4. Evidently exports model drift metrics to Prometheus
5. Grafana dashboards visualize prediction accuracy, drift metrics, and system metrics

---

## ğŸ–¥ï¸ System Architecture (Mermaid)

```mermaid
graph TD
  subgraph User Interaction
    A[Frontend<br>React]
    A -->|HTTP Request| B[Backend<br>FastAPI]
  end

  subgraph Real-time Inference
    B -->|Query Data| D[PostgreSQL]
    B -->|Cached Query| E[Redis]
    B -->|Call| C[Model Runner<br>Load + Predict]
  end

  subgraph Batch Processing & Training
    F[Workflow<br>Prefect]
    F -->|Run| G[ETL/Train<br>Data + Model]
    G -->|Log Results| H[MLflow Registry]
    G -->|Update DB| D
  end

  subgraph Model Monitoring
    I[monitor.py<br>Evidently Exporter]
    I -->|Metrics| J[Prometheus]
    J -->|Datasource| K[Grafana Dashboard]
    I -->|Drift Detection| D
  end
```

---

## ğŸ“ˆ Evaluation Checklist

### âœ… Problem Definition

* âœ”ï¸ Well-defined scope: stock prediction + model lifecycle

### â˜ï¸ Infrastructure

* âœ”ï¸ Docker Compose setup with multiple services
* âœ”ï¸ Cloud-ready and IaC-friendly (MinIO, DB volumes, Prometheus)

### ğŸ”¬ Experiment Tracking

* âœ”ï¸ MLflow for logging experiments and model versioning

### ğŸ“… Workflow Orchestration

* âœ”ï¸ Prefect 2 for ETL and training flows

### ğŸš€ Model Deployment

* âœ”ï¸ FastAPI for model inference (containerized API)

### ğŸ“Š Monitoring

* âœ”ï¸ Evidently + Prometheus + Grafana for data/model monitoring

### ğŸ” Reproducibility

* âœ”ï¸ Makefile + setup.md + requirements + Docker for consistent setup

### ğŸ§ª Best Practices

* [x] Unit tests
* [x] Integration tests
* [x] Code formatting (black, flake8)
* [x] Makefile automation
* [x] Pre-commit hooks
* [x] GitHub Actions for CI

---

## âš™ï¸ Installation Guide

```bash
# Create virtual environment
python -m venv .venv
source .venv/bin/activate
pip install -r backend/requirements.txt

# Start all services
docker compose up --build

# Run Prefect workflow or one-off training
make train
make workflow
```

---

## ğŸ“Š Dataset

Historical stock data from TW & US markets (e.g., 2330.TW, AAPL, TSM):

* Source: Yahoo Finance
* Transformed via ETL and stored in Parquet format (see `workflows/parquet/`)

---

## ğŸ”— Useful Resources

* [MLFlow Documentation](https://mlflow.org/)
* [Evidently AI Docs](https://docs.evidentlyai.com/)
* [Prefect 2 Docs](https://docs.prefect.io/)
* [Grafana Dashboards](https://grafana.com/grafana/dashboards)

---

## ğŸ“œ License

MIT License.
