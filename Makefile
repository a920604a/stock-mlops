# ========================
# Global Config & Variables
# ========================

DOCKER_COMPOSE            = docker compose
COMPOSE_DB                = docker compose -f docker-compose.database.yml
COMPOSE_KAFKA             = docker compose -f docker-compose.kafka.yml
COMPOSE_BACKEND           = docker compose -f docker-compose.backend.yml
COMPOSE_FRONTEND          = docker compose -f docker-compose.frontend.yml
COMPOSE_MONITOR           = docker compose -f docker-compose.monitor.yml

NETWORK_NAME              = monitor-net

TRAIN_BACKEND             = backend1
PREDICT_BACKEND           = backend2
BACKENDS                  = $(TRAIN_BACKEND) $(PREDICT_BACKEND)

FRONTEND_DIR              = frontend
DB_DIRS                   = db/mlflow_db db/oltp db/model_meta_db db/olap
DATA_DIRS                 = data/mlflow_artifacts data/prometheus_data data/minio

LOCAL_TAG                 = $(shell date +"%Y-%m-%d-%H-%M")
LOCAL_IMAGE_NAME          = stock-mlops-backend:${LOCAL_TAG}

MAKEFLAGS += --no-builtin-rules

.PHONY: help init init-soft net-create clean reset restart \
        up-core up-db up-kafka up-backend up-frontend up-monitor \
        down-all down-core down-db down-kafka down-backend down-frontend down-monitor \
        logs-backend logs-monitor logs-db logs-kafka logs-frontend \
        setup build all up-all ingest test train predict monitor \
        integration_test quality_checks pipeline retrain ci publish \
        frontend-dev frontend-build \
        monitor-up monitor-down monitor-logs dev-setup

# ========================
# Help
# ========================
help:
	@echo "ğŸ“¦ å¯ç”¨æŒ‡ä»¤å¦‚ä¸‹ï¼š"
	@grep -E '^[a-zA-Z0-9_\-]+:.*?##' Makefile | awk 'BEGIN {FS = ":.*?##"} {printf "  \033[36m%-22s\033[0m %s\n", $$1, $$2}'

# ========================
# Init / Clean
# ========================

net-create: ## å»ºç«‹å…±ç”¨ Docker networkï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰
	@echo "ğŸ”Œ æª¢æŸ¥/å»ºç«‹ network $(NETWORK_NAME)"
	@if ! docker network inspect $(NETWORK_NAME) >/dev/null 2>&1; then \
		docker network create $(NETWORK_NAME) --driver bridge; \
		echo "âœ… å»ºç«‹ $(NETWORK_NAME) å®Œæˆ"; \
	else \
		echo "âœ… $(NETWORK_NAME) å·²å­˜åœ¨"; \
	fi

init: ## åˆå§‹åŒ–è³‡æ–™å¤¾ï¼ˆå« networkï¼‰
	$(MAKE) net-create
	mkdir -p $(DB_DIRS)
	mkdir -p $(DATA_DIRS)

init-soft: ## åƒ…å»ºç«‹ networkï¼ˆä¸å»ºç«‹è³‡æ–™å¤¾ï¼‰
	$(MAKE) net-create

clean: ## æ¸…é™¤æ‰€æœ‰å®¹å™¨èˆ‡è³‡æ–™å¤¾ï¼ˆå°å¿ƒæœƒåˆªè³‡æ–™ï¼‰
	$(MAKE) down-all
	sudo rm -rf $(DB_DIRS) $(DATA_DIRS)
	rm -rf $(FRONTEND_DIR)/package-lock.json $(FRONTEND_DIR)/node_modules

reset: ## æ¸…é™¤ä¸¦é‡æ–°å•Ÿå‹•æ ¸å¿ƒï¼ˆDB + Kafka + Backendï¼‰
	@echo "ğŸ§¹ reset æ ¸å¿ƒæœå‹™ (DB/Kafka/Backend)"
	$(MAKE) down-core
	$(MAKE) init
	$(MAKE) up-core
	@echo "âœ… reset å®Œæˆ"

restart: ## å¿«é€Ÿé‡å•Ÿ backend å®¹å™¨ï¼ˆä¸é‡å»º imageï¼‰
	$(COMPOSE_BACKEND) restart $(BACKENDS)

# ========================
# Up / Down (åˆ†çµ„æ§åˆ¶)
# ========================

# --- UP ---

up-db: ## å•Ÿå‹•è³‡æ–™åº« (Redis/Postgres/ClickHouse/MinIO/MLflow-DB ...)
	$(COMPOSE_DB) up -d

up-kafka: ## å•Ÿå‹• Kafka
	$(COMPOSE_KAFKA) up -d

up-backend: ## å•Ÿå‹•å¾Œç«¯èˆ‡ Celeryï¼ˆéœ€ DB & Kafka å·²èµ·ä¾†ï¼‰
	$(COMPOSE_BACKEND) up -d

up-frontend: ## å•Ÿå‹•å‰ç«¯èˆ‡ UI
	$(COMPOSE_FRONTEND) up -d

up-monitor: ## å•Ÿå‹•ç›£æ§æ¨¡çµ„ï¼ˆPrometheus, Grafana, exporters...ï¼‰
	$(COMPOSE_MONITOR) up -d

# up-core: up-db up-kafka up-backend ## ä¾åºå•Ÿå‹•æ ¸å¿ƒæœå‹™ï¼ˆDB â†’ Kafka â†’ Backendï¼‰
up-core:
	docker compose -f docker-compose.database.yml \
	               -f docker-compose.celery.yml \
				   -f docker-compose.kafka.yml \
	               -f docker-compose.backend.yml \
	               up -d

up-all: ## ä¾åºå•Ÿå‹•æ‰€æœ‰æœå‹™(æ ¸å¿ƒ + å‰ç«¯ + ç›£æ§)
	$(MAKE) up-core
	$(MAKE) up-frontend
	$(MAKE) up-monitor
	@echo "ğŸš€ æ‰€æœ‰æœå‹™å·²å•Ÿå‹•"

# --- DOWN ---

down-db:
	$(COMPOSE_DB) down

down-kafka:
	$(COMPOSE_KAFKA) down

down-backend:
	$(COMPOSE_BACKEND) down

down-frontend:
	$(COMPOSE_FRONTEND) down

down-monitor:
	$(COMPOSE_MONITOR) down

down-core:
	docker compose -f docker-compose.database.yml \
	               -f docker-compose.celery.yml \
	               -f docker-compose.kafka.yml \
	               -f docker-compose.backend.yml \
	               down


down-all: ## é—œé–‰æ‰€æœ‰æœå‹™ï¼ˆMonitor â†’ Frontend â†’ Backend â†’ Kafka â†’ DBï¼‰
	$(MAKE) down-monitor || true
	$(MAKE) down-frontend || true
	$(MAKE) down-backend || true
	$(MAKE) down-kafka || true
	$(MAKE) down-db || true
	@echo "ğŸ›‘ æ‰€æœ‰æœå‹™å·²é—œé–‰"

# ========================
# Logs
# ========================

logs-backend: ## è¿½ backend1 & backend2 æ—¥èªŒ
	$(COMPOSE_BACKEND) logs -f $(BACKENDS)

logs-monitor: ## è¿½ç›£æ§æ¨¡çµ„æ—¥èªŒ
	$(COMPOSE_MONITOR) logs -f

logs-db:
	$(COMPOSE_DB) logs -f

logs-kafka:
	$(COMPOSE_KAFKA) logs -f

logs-frontend:
	$(COMPOSE_FRONTEND) logs -f

# èˆ‡ä½ åŸæœ¬å…¼å®¹çš„åˆ¥å
monitor-up: up-monitor ## å•Ÿå‹•ç›£æ§æ¨¡çµ„ï¼ˆPrometheus, Grafana ç­‰ï¼‰
	@echo "ğŸ“ˆ ç›£æ§æ¨¡çµ„å·²å•Ÿå‹•"

monitor-down: down-monitor ## é—œé–‰ç›£æ§æ¨¡çµ„

monitor-logs: logs-monitor ## æŸ¥çœ‹ç›£æ§æ¨¡çµ„æ—¥èªŒ

# ========================
# Project Ops
# ========================

frontend-dev: ## å•Ÿå‹•å‰ç«¯é–‹ç™¼æ¨¡å¼
	cd $(FRONTEND_DIR) && npm install && npm run dev

frontend-build: ## å‰ç«¯æ­£å¼ç‰ˆç·¨è­¯
	cd $(FRONTEND_DIR) && npm install && npm run build

ingest: ## åŸ·è¡Œè³‡æ–™æ”¶é›†è…³æœ¬
	bash scripts/ingest.sh

train: ## åŸ·è¡Œæ¨¡å‹è¨“ç·´
	@echo "ğŸš€ åŸ·è¡Œæ¨¡å‹è¨“ç·´..."
	$(COMPOSE_BACKEND) exec $(TRAIN_BACKEND) python src/model_training/train.py || (echo "âŒ è¨“ç·´å¤±æ•—"; exit 1)

predict: ## åŸ·è¡Œæ¨¡å‹æ¨è«–
	$(COMPOSE_BACKEND) exec $(PREDICT_BACKEND) python src/inference/predict.py

monitor: ## æ¨¡æ“¬ç›£æ§
	$(COMPOSE_BACKEND) exec $(PREDICT_BACKEND) python src/inference/simulate_predict_days.py --start-date 2025-06-01 --days 15 --ticker AAPL --exchange US --base-url http://localhost:8000
	@echo "ğŸ“Š æ¨¡æ“¬ç›£æ§å·²å®Œæˆ"

# ========================
# Tests & Quality
# ========================

test: ## å–®å…ƒæ¸¬è©¦
	$(COMPOSE_BACKEND) exec $(TRAIN_BACKEND) pytest -v

quality_checks: ## ç¨‹å¼ç¢¼é¢¨æ ¼æª¢æŸ¥ï¼ˆisort / black / pylintï¼‰
	isort .
	black .
	pylint backend/src || true

integration_test: ## æ•´åˆæ¸¬è©¦
	$(COMPOSE_BACKEND) exec $(PREDICT_BACKEND) pytest integraton-test/test_predict_api.py

pipeline: quality_checks test train predict ## æ¨¡å‹å®Œæ•´é–‹ç™¼æµç¨‹

retrain: train predict ## è¨“ç·´èˆ‡é æ¸¬

ci: quality_checks test integration_test ## CI/CD æª¢æŸ¥èˆ‡æ¸¬è©¦æµç¨‹

publish: quality_checks build ## å“è³ªæª¢æŸ¥èˆ‡å»ºç½®å¾Œç™¼å¸ƒ
	LOCAL_IMAGE_NAME=$(LOCAL_IMAGE_NAME) bash scripts/publish.sh

# ========================
# High-level Flows
# ========================

setup: clean init up-all ingest ## ä¸€éµå•Ÿå‹•æ•´å¥—ï¼ˆå«ç›£æ§ï¼‰

build: init up-core ## æ ¸å¿ƒå»ºç½®èˆ‡å•Ÿå‹•

all: init up-core ingest ## èˆ‡å‚³çµ± all åŒç¾©

dev-setup: ## æœ¬åœ°é–‹ç™¼å¿«é€Ÿé‡ä¾†ï¼ˆåœç›£æ§ â†’ reset æ ¸å¿ƒ â†’ ingest â†’ å•Ÿç›£æ§ï¼‰
	$(MAKE) monitor-down
	$(MAKE) reset
	$(MAKE) ingest
	$(MAKE) up-frontend
	$(MAKE) monitor-up


# make up-core
# make up-frontend
# make up-monitor
