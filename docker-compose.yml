services:
  nginx:
    build:
      context: .
      dockerfile: ./Dockerfile.nginx
    container_name: nginx
    ports:
      - "80:80"
    depends_on:
      - backend1
      - backend2
    networks:
      - monitor-net

  backend1:
    build:
      context: ./backend
      dockerfile: ../Dockerfile.backend
    container_name: backend1
    ports:
      - "8001:8000"
    depends_on:
      - raw_db
      - redis
      - mlflow
      - kafka
    environment:
      - DATABASE_URL=postgresql://user:password@model_meta_db:5432/stocks
      - REDIS_HOST=redis
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - CLICKHOUSE_HOST=clickhouse
      - CLICKHOUSE_PORT=9000
      - CLICKHOUSE_PASSWORD=
      - CLICKHOUSE_DB=default
      - AWS_ACCESS_KEY_ID=mlflow
      - AWS_SECRET_ACCESS_KEY=mlflow123
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
    volumes:
      - ./backend:/app
    networks:
      - monitor-net

  backend2:
    build:
      context: ./backend
      dockerfile: ../Dockerfile.backend
    container_name: backend2
    ports:
      - "8002:8000"
    depends_on:
      - raw_db
      - redis
      - mlflow
      - kafka
    environment:
      - DATABASE_URL=postgresql://user:password@model_meta_db:5432/stocks
      - REDIS_HOST=redis
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - CLICKHOUSE_HOST=clickhouse
      - CLICKHOUSE_PORT=9000
      - CLICKHOUSE_PASSWORD=
      - CLICKHOUSE_DB=default
      - AWS_ACCESS_KEY_ID=mlflow
      - AWS_SECRET_ACCESS_KEY=mlflow123
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
    volumes:
      - ./backend:/app
    networks:
      - monitor-net

  raw_db: # save raw data OLTP
    image: postgres:15
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: stocks
    ports:
      - "5412:5432"
    volumes:
      - ./db/oltp:/var/lib/postgresql/data
    networks:
      - monitor-net

  model_meta_db: # save model meta data
    image: postgres:15
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: stocks
    ports:
      - "5411:5432"
    volumes:
      - ./db/model_meta_db:/var/lib/postgresql/data
      - ./db/init-scripts:/docker-entrypoint-initdb.d:ro
    networks:
      - monitor-net

  redis:
    image: redis:7
    ports:
      - "6379:6379"
    networks:
      - monitor-net

  celery_train:
    build:
      context: ./backend
      dockerfile: ../Dockerfile.backend
    container_name: celery_train
    command: celery -A celery_worker.celery_app worker -Q train_queue -n worker.train@%h --loglevel=info --events

    environment:
      - DATABASE_URL=postgresql://user:password@model_meta_db:5432/stocks
      - REDIS_HOST=redis
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - CLICKHOUSE_HOST=clickhouse
      - CLICKHOUSE_PORT=9000
      - CLICKHOUSE_PASSWORD=
      - CLICKHOUSE_DB=default
      - AWS_ACCESS_KEY_ID=mlflow
      - AWS_SECRET_ACCESS_KEY=mlflow123
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - PROMETHEUS_MULTIPROC_DIR=/tmp/celery_metrics # 必須設置，用於多進程模式
    depends_on:
      - redis
      - backend1
      - backend2
    volumes:
      - ./backend:/app
    networks:
      - monitor-net
  celery_predict:
    build:
      context: ./backend
      dockerfile: ../Dockerfile.backend
    container_name: celery_predict
    command: celery -A celery_worker.celery_app worker -Q predict_queue -n worker.predict@%h --loglevel=info --events
    environment:
      - DATABASE_URL=postgresql://user:password@model_meta_db:5432/stocks
      - REDIS_HOST=redis
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - CLICKHOUSE_HOST=clickhouse
      - CLICKHOUSE_PORT=9000
      - CLICKHOUSE_PASSWORD=
      - CLICKHOUSE_DB=default
      - AWS_ACCESS_KEY_ID=mlflow
      - AWS_SECRET_ACCESS_KEY=mlflow123
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - PROMETHEUS_MULTIPROC_DIR=/tmp/celery_metrics # 必須設置，用於多進程模式
    depends_on:
      - redis
      - backend1
      - backend2
    volumes:
      - ./backend:/app
    networks:
      - monitor-net
  flower:
    image: mher/flower:0.9.7
    container_name: flower

    command: flower --broker=redis://redis:6379/0 --port=5555
    ports:
      - "5555:5555"
    depends_on:
      - redis
    networks:
      - monitor-net

  mlflow:
    build:
      context: .
      dockerfile: Dockerfile.mlflow
    depends_on:
      - mlflow-db
    environment:
      AWS_ACCESS_KEY_ID: mlflow
      AWS_SECRET_ACCESS_KEY: mlflow123
      MLFLOW_ARTIFACT_ROOT: s3://mlflow-artifacts
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri postgresql://mlflow:mlflow@mlflow-db:5432/mlflow
      --default-artifact-root s3://mlflow-artifacts
    ports:
      - "5010:5000"
    networks:
      - monitor-net

  mlflow-db:
    image: postgres:15
    environment:
      POSTGRES_USER: mlflow
      POSTGRES_PASSWORD: mlflow
      POSTGRES_DB: mlflow
    volumes:
      - ./db/mlflow_db:/var/lib/postgresql/data
    ports:
      - "5422:5432"
    networks:
      - monitor-net

  clickhouse:
    image: clickhouse/clickhouse-server:23.3
    ports:
      - "8123:8123" # HTTP 接口 (可用 DBeaver 連線) , http://localhost:8123/play, http://localhost:8123/dashboard
      - "9000:9000" # Native TCP 協議
    volumes:
      - ./db/olap/clickhouse_data:/var/lib/clickhouse
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    networks:
      - monitor-net

  minio:
    image: minio/minio
    container_name: minio
    command: server /data --console-address ":9001"
    ports:
      - "9111:9000" # API
      - "9001:9001" # 控制台, 進入 MinIO web 控制台（http://localhost:9001）登入後： 建立一個 bucket 名為：mlflow-artifacts
    environment:
      - MINIO_ROOT_USER=mlflow
      - MINIO_ROOT_PASSWORD=mlflow123
    volumes:
      - ./data/minio:/data
    networks:
      - monitor-net
  init-minio:
    image: minio/mc
    depends_on:
      - minio
    entrypoint: /bin/sh
    command: /scripts/init_minio.sh
    environment:
      MINIO_ROOT_USER: mlflow
      MINIO_ROOT_PASSWORD: mlflow123
    volumes:
      - ./scripts/init_minio.sh:/scripts/init_minio.sh:ro
    networks:
      - monitor-net
  ws_monitor:
    build:
      context: ./ws_monitor
      dockerfile: ../Dockerfile.ws_monitor
    container_name: ws_monitor
    ports:
      - "8010:8000"
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - CLICKHOUSE_HOST=clickhouse
      - CLICKHOUSE_PORT=9000 # 預設是連接 ClickHouse 的 TCP 端口（9000）
      - CLICKHOUSE_PASSWORD=
      - CLICKHOUSE_DB=default
    volumes:
      - ./ws_monitor:/app
    depends_on:
      - kafka
    networks:
      - monitor-net

  metrics_publisher:
    build:
      context: ./metrics_publisher
      dockerfile: ../Dockerfile.metrics_publisher
    container_name: metrics_publisher
    depends_on:
      - backend1
      - kafka
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - PROMETHEUS_ENDPOINT=http://backend1:8000/metrics
    networks:
      - monitor-net
  kafka:
    image: apache/kafka:3.9.1
    environment:
      - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      - KAFKA_LISTENER_NAME_CONTROLLER_LISTENER_SECURITY_PROTOCOL=PLAINTEXT
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_NODE_ID=1
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
    ports:
      - "9092:9092"
    networks:
      - monitor-net

  celery_exporter: # 新增的 Celery Prometheus Exporter 服務
    image: ghcr.io/danihodovic/celery-exporter:latest # 使用預構建的 Docker 鏡像
    container_name: celery_exporter
    ports:
      - "8000:9540" # 將容器的 8000 端口映射到主機的 8000 端口
    environment:
      - CE_BROKER_URL=redis://redis:6379/0 # 連接到 Celery broker (Redis 服務)
      - CE_LISTEN_PORT=8000 # Exporter 監聽的端口
      - CE_ENABLE_EVENTS=true # 啟用事件監聽
    depends_on:
      - redis # 依賴於 Redis broker
      - celery_train
      - celery_predict # 依賴於  worker 確保其啟動並發送事件
    networks:
      - monitor-net

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
      # 若有 SASL/SSL 等安全需求，可再加上 *_PROPERTIES_* 參數
      # - KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL=SASL_PLAINTEXT
      # - KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM=SCRAM-SHA-512
      # - KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG=org.apache.kafka.common.security.scram.ScramLoginModule required username="user" password="pass";
      - DYNAMIC_CONFIG_ENABLED=true # 可選，允許於 UI 動態新增集群
      # （可選）開啟簡單登入保護
      - KAFKA_UI_AUTH_USERNAME=admin
      - KAFKA_UI_LOGIN_PTYPE=LOGIN_FORM
      - KAFKA_UI_LOGIN_ASSWORD=admin
    ports:
      - "8082:8080"
    depends_on:
      - kafka
    networks:
      - monitor-net

networks:
  monitor-net:
    name: monitor-net
    driver: bridge
